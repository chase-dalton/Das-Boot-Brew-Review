{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size_l</th>\n",
       "      <th>og</th>\n",
       "      <th>fg</th>\n",
       "      <th>abv</th>\n",
       "      <th>ibu</th>\n",
       "      <th>color</th>\n",
       "      <th>boilsize</th>\n",
       "      <th>boiltime</th>\n",
       "      <th>boilgravity</th>\n",
       "      <th>efficiency</th>\n",
       "      <th>mashthickness</th>\n",
       "      <th>pitchrate</th>\n",
       "      <th>primarytemp</th>\n",
       "      <th>review_taste</th>\n",
       "      <th>beer_abv</th>\n",
       "      <th>sugarscale_Plato</th>\n",
       "      <th>sugarscale_Specific Gravity</th>\n",
       "      <th>brewmethod_All Grain</th>\n",
       "      <th>brewmethod_BIAB</th>\n",
       "      <th>brewmethod_Partial Mash</th>\n",
       "      <th>brewmethod_extract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.93</td>\n",
       "      <td>1.082</td>\n",
       "      <td>1.013</td>\n",
       "      <td>9.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.10</td>\n",
       "      <td>21.58</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.103825</td>\n",
       "      <td>7.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.57</td>\n",
       "      <td>1.076</td>\n",
       "      <td>1.014</td>\n",
       "      <td>8.10</td>\n",
       "      <td>33.51</td>\n",
       "      <td>3.68</td>\n",
       "      <td>8.71</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.066</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.103825</td>\n",
       "      <td>7.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.82</td>\n",
       "      <td>1.043</td>\n",
       "      <td>1.011</td>\n",
       "      <td>4.14</td>\n",
       "      <td>13.22</td>\n",
       "      <td>17.67</td>\n",
       "      <td>28.39</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>12.22</td>\n",
       "      <td>3.028652</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22.71</td>\n",
       "      <td>1.069</td>\n",
       "      <td>1.017</td>\n",
       "      <td>6.75</td>\n",
       "      <td>58.76</td>\n",
       "      <td>40.00</td>\n",
       "      <td>29.34</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.053</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.265971</td>\n",
       "      <td>6.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22.71</td>\n",
       "      <td>1.068</td>\n",
       "      <td>1.018</td>\n",
       "      <td>6.53</td>\n",
       "      <td>73.40</td>\n",
       "      <td>40.00</td>\n",
       "      <td>27.44</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.056</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.25</td>\n",
       "      <td>18.89</td>\n",
       "      <td>4.265971</td>\n",
       "      <td>6.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   size_l     og     fg   abv    ibu  color  boilsize  boiltime  boilgravity  \\\n",
       "0   18.93  1.082  1.013  9.10   0.00   4.10     21.58      60.0        0.000   \n",
       "1    7.57  1.076  1.014  8.10  33.51   3.68      8.71      60.0        1.066   \n",
       "2   20.82  1.043  1.011  4.14  13.22  17.67     28.39      90.0        0.000   \n",
       "3   22.71  1.069  1.017  6.75  58.76  40.00     29.34      90.0        1.053   \n",
       "4   22.71  1.068  1.018  6.53  73.40  40.00     27.44      90.0        1.056   \n",
       "\n",
       "   efficiency  mashthickness  pitchrate  primarytemp  review_taste  beer_abv  \\\n",
       "0        72.0            0.0       0.00         0.00      4.103825       7.6   \n",
       "1        75.0            0.0       0.00         0.00      4.103825       7.6   \n",
       "2        85.0            0.0       1.75        12.22      3.028652       4.4   \n",
       "3        70.0            0.0       0.00         0.00      4.265971       6.4   \n",
       "4        65.0            1.3       1.25        18.89      4.265971       6.4   \n",
       "\n",
       "   sugarscale_Plato  sugarscale_Specific Gravity  brewmethod_All Grain  \\\n",
       "0               0.0                          1.0                   1.0   \n",
       "1               0.0                          1.0                   1.0   \n",
       "2               0.0                          1.0                   1.0   \n",
       "3               0.0                          1.0                   1.0   \n",
       "4               0.0                          1.0                   1.0   \n",
       "\n",
       "   brewmethod_BIAB  brewmethod_Partial Mash  brewmethod_extract  \n",
       "0              0.0                      0.0                 0.0  \n",
       "1              0.0                      0.0                 0.0  \n",
       "2              0.0                      0.0                 0.0  \n",
       "3              0.0                      0.0                 0.0  \n",
       "4              0.0                      0.0                 0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_nb_df = pd.read_csv(\"merged_nb_df.csv\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "merged_nb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34.77543538038497"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What percentage of beers scored 4 or above?\n",
    "len(merged_nb_df[(merged_nb_df[\"review_taste\"]>=4)]) / len(merged_nb_df) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since beers with a rating of four or above is the top 34% of beers, let's go with those as \"good\" beers.\n",
    "# We need a new category \"good beer\" with a 1 for good and 0 for bad\n",
    "merged_nb_df[\"good_beer\"]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for all the \"good beers\", put a 1 in the good_beer column\n",
    "merged_nb_df.loc[merged_nb_df[\"review_taste\"].abs()>=4, \"good_beer\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size_l</th>\n",
       "      <th>og</th>\n",
       "      <th>fg</th>\n",
       "      <th>abv</th>\n",
       "      <th>ibu</th>\n",
       "      <th>color</th>\n",
       "      <th>boilsize</th>\n",
       "      <th>boiltime</th>\n",
       "      <th>boilgravity</th>\n",
       "      <th>efficiency</th>\n",
       "      <th>mashthickness</th>\n",
       "      <th>pitchrate</th>\n",
       "      <th>primarytemp</th>\n",
       "      <th>review_taste</th>\n",
       "      <th>beer_abv</th>\n",
       "      <th>sugarscale_Plato</th>\n",
       "      <th>sugarscale_Specific Gravity</th>\n",
       "      <th>brewmethod_All Grain</th>\n",
       "      <th>brewmethod_BIAB</th>\n",
       "      <th>brewmethod_Partial Mash</th>\n",
       "      <th>brewmethod_extract</th>\n",
       "      <th>good_beer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.93</td>\n",
       "      <td>1.082</td>\n",
       "      <td>1.013</td>\n",
       "      <td>9.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.10</td>\n",
       "      <td>21.58</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.103825</td>\n",
       "      <td>7.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.57</td>\n",
       "      <td>1.076</td>\n",
       "      <td>1.014</td>\n",
       "      <td>8.10</td>\n",
       "      <td>33.51</td>\n",
       "      <td>3.68</td>\n",
       "      <td>8.71</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.066</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.103825</td>\n",
       "      <td>7.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.82</td>\n",
       "      <td>1.043</td>\n",
       "      <td>1.011</td>\n",
       "      <td>4.14</td>\n",
       "      <td>13.22</td>\n",
       "      <td>17.67</td>\n",
       "      <td>28.39</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>12.22</td>\n",
       "      <td>3.028652</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22.71</td>\n",
       "      <td>1.069</td>\n",
       "      <td>1.017</td>\n",
       "      <td>6.75</td>\n",
       "      <td>58.76</td>\n",
       "      <td>40.00</td>\n",
       "      <td>29.34</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.053</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.265971</td>\n",
       "      <td>6.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22.71</td>\n",
       "      <td>1.068</td>\n",
       "      <td>1.018</td>\n",
       "      <td>6.53</td>\n",
       "      <td>73.40</td>\n",
       "      <td>40.00</td>\n",
       "      <td>27.44</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.056</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.25</td>\n",
       "      <td>18.89</td>\n",
       "      <td>4.265971</td>\n",
       "      <td>6.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   size_l     og     fg   abv    ibu  color  boilsize  boiltime  boilgravity  \\\n",
       "0   18.93  1.082  1.013  9.10   0.00   4.10     21.58      60.0        0.000   \n",
       "1    7.57  1.076  1.014  8.10  33.51   3.68      8.71      60.0        1.066   \n",
       "2   20.82  1.043  1.011  4.14  13.22  17.67     28.39      90.0        0.000   \n",
       "3   22.71  1.069  1.017  6.75  58.76  40.00     29.34      90.0        1.053   \n",
       "4   22.71  1.068  1.018  6.53  73.40  40.00     27.44      90.0        1.056   \n",
       "\n",
       "   efficiency  mashthickness  pitchrate  primarytemp  review_taste  beer_abv  \\\n",
       "0        72.0            0.0       0.00         0.00      4.103825       7.6   \n",
       "1        75.0            0.0       0.00         0.00      4.103825       7.6   \n",
       "2        85.0            0.0       1.75        12.22      3.028652       4.4   \n",
       "3        70.0            0.0       0.00         0.00      4.265971       6.4   \n",
       "4        65.0            1.3       1.25        18.89      4.265971       6.4   \n",
       "\n",
       "   sugarscale_Plato  sugarscale_Specific Gravity  brewmethod_All Grain  \\\n",
       "0               0.0                          1.0                   1.0   \n",
       "1               0.0                          1.0                   1.0   \n",
       "2               0.0                          1.0                   1.0   \n",
       "3               0.0                          1.0                   1.0   \n",
       "4               0.0                          1.0                   1.0   \n",
       "\n",
       "   brewmethod_BIAB  brewmethod_Partial Mash  brewmethod_extract  good_beer  \n",
       "0              0.0                      0.0                 0.0          1  \n",
       "1              0.0                      0.0                 0.0          1  \n",
       "2              0.0                      0.0                 0.0          0  \n",
       "3              0.0                      0.0                 0.0          1  \n",
       "4              0.0                      0.0                 0.0          1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_nb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "beer_class = merged_nb_df.drop(columns = [\"review_taste\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = beer_class.good_beer.values\n",
    "X = beer_class.drop(columns = [\"good_beer\"]).values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=5, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Random forest predictive accuracy: 0.613\n"
     ]
    }
   ],
   "source": [
    "# Create a random forest classifier.\n",
    "rf_model = RandomForestClassifier(n_estimators=200, random_state=5)\n",
    "\n",
    "# Fitting the model\n",
    "rf_model = rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = rf_model.predict(X_test_scaled)\n",
    "print(f\" Random forest predictive accuracy: {accuracy_score(y_test,y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.69      0.74      0.37      0.71      0.52      0.28      1779\n",
      "          1       0.43      0.37      0.74      0.40      0.52      0.26       949\n",
      "\n",
      "avg / total       0.60      0.61      0.50      0.60      0.52      0.28      2728\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the imbalanced classification report\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Easy Ensemble Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EasyEnsembleClassifier(n_estimators=100, random_state=1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the EasyEnsembleClassifier\n",
    "classifier = EasyEnsembleClassifier(n_estimators = 100, random_state=1)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.6873167155425219\n"
     ]
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "predictions = classifier.predict(X_test)\n",
    "acc_score = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy Score : {acc_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>1284</td>\n",
       "      <td>495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>358</td>\n",
       "      <td>591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0         1284          495\n",
       "Actual 1          358          591"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual 0\", \"Actual 1\"],\n",
    "    columns=[\"Predicted 0\", \"Predicted 1\"]\n",
    ")\n",
    "\n",
    "# Displaying results\n",
    "display(cm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.78      0.72      0.62      0.75      0.67      0.45      1779\n",
      "          1       0.54      0.62      0.72      0.58      0.67      0.45       949\n",
      "\n",
      "avg / total       0.70      0.69      0.66      0.69      0.67      0.45      2728\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the imbalanced classification report\n",
    "print(\"Classification Report\")\n",
    "print(classification_report_imbalanced(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 50)                1050      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                1020      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 2,091\n",
      "Trainable params: 2,091\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = 20\n",
    "hidden_nodes_layer1 = 50\n",
    "hidden_nodes_layer2 = 20\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the Sequential model together and customize metrics\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "256/256 [==============================] - 1s 708us/step - loss: 0.6432 - accuracy: 0.6457\n",
      "Epoch 2/100\n",
      "256/256 [==============================] - 0s 739us/step - loss: 0.6284 - accuracy: 0.6513\n",
      "Epoch 3/100\n",
      "256/256 [==============================] - 0s 743us/step - loss: 0.6242 - accuracy: 0.6540\n",
      "Epoch 4/100\n",
      "256/256 [==============================] - 0s 735us/step - loss: 0.6205 - accuracy: 0.6567\n",
      "Epoch 5/100\n",
      "256/256 [==============================] - 0s 744us/step - loss: 0.6188 - accuracy: 0.6622\n",
      "Epoch 6/100\n",
      "256/256 [==============================] - 0s 715us/step - loss: 0.6160 - accuracy: 0.6637\n",
      "Epoch 7/100\n",
      "256/256 [==============================] - 0s 719us/step - loss: 0.6160 - accuracy: 0.6660\n",
      "Epoch 8/100\n",
      "256/256 [==============================] - 0s 750us/step - loss: 0.6143 - accuracy: 0.6665\n",
      "Epoch 9/100\n",
      "256/256 [==============================] - 0s 723us/step - loss: 0.6129 - accuracy: 0.6689\n",
      "Epoch 10/100\n",
      "256/256 [==============================] - 0s 727us/step - loss: 0.6119 - accuracy: 0.6695\n",
      "Epoch 11/100\n",
      "256/256 [==============================] - 0s 750us/step - loss: 0.6109 - accuracy: 0.6706\n",
      "Epoch 12/100\n",
      "256/256 [==============================] - 0s 778us/step - loss: 0.6096 - accuracy: 0.6709\n",
      "Epoch 13/100\n",
      "256/256 [==============================] - 0s 786us/step - loss: 0.6087 - accuracy: 0.6736\n",
      "Epoch 14/100\n",
      "256/256 [==============================] - 0s 735us/step - loss: 0.6077 - accuracy: 0.6753\n",
      "Epoch 15/100\n",
      "256/256 [==============================] - 0s 864us/step - loss: 0.6064 - accuracy: 0.6742\n",
      "Epoch 16/100\n",
      "256/256 [==============================] - 0s 879us/step - loss: 0.6051 - accuracy: 0.6748\n",
      "Epoch 17/100\n",
      "256/256 [==============================] - 0s 834us/step - loss: 0.6045 - accuracy: 0.6753\n",
      "Epoch 18/100\n",
      "256/256 [==============================] - 0s 800us/step - loss: 0.6028 - accuracy: 0.6800\n",
      "Epoch 19/100\n",
      "256/256 [==============================] - 0s 793us/step - loss: 0.6026 - accuracy: 0.6793\n",
      "Epoch 20/100\n",
      "256/256 [==============================] - 0s 793us/step - loss: 0.6015 - accuracy: 0.6773\n",
      "Epoch 21/100\n",
      "256/256 [==============================] - 0s 798us/step - loss: 0.6009 - accuracy: 0.6819\n",
      "Epoch 22/100\n",
      "256/256 [==============================] - 0s 804us/step - loss: 0.5993 - accuracy: 0.6791\n",
      "Epoch 23/100\n",
      "256/256 [==============================] - 0s 832us/step - loss: 0.5992 - accuracy: 0.6778\n",
      "Epoch 24/100\n",
      "256/256 [==============================] - 0s 860us/step - loss: 0.5977 - accuracy: 0.6803\n",
      "Epoch 25/100\n",
      "256/256 [==============================] - 0s 829us/step - loss: 0.5973 - accuracy: 0.6800\n",
      "Epoch 26/100\n",
      "256/256 [==============================] - 0s 797us/step - loss: 0.5959 - accuracy: 0.6813\n",
      "Epoch 27/100\n",
      "256/256 [==============================] - 0s 821us/step - loss: 0.5950 - accuracy: 0.6797\n",
      "Epoch 28/100\n",
      "256/256 [==============================] - 0s 790us/step - loss: 0.5937 - accuracy: 0.6811\n",
      "Epoch 29/100\n",
      "256/256 [==============================] - 0s 734us/step - loss: 0.5927 - accuracy: 0.6830\n",
      "Epoch 30/100\n",
      "256/256 [==============================] - 0s 747us/step - loss: 0.5920 - accuracy: 0.6837\n",
      "Epoch 31/100\n",
      "256/256 [==============================] - 0s 796us/step - loss: 0.5921 - accuracy: 0.6816\n",
      "Epoch 32/100\n",
      "256/256 [==============================] - 0s 770us/step - loss: 0.5897 - accuracy: 0.6816\n",
      "Epoch 33/100\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.5890 - accuracy: 0.6843\n",
      "Epoch 34/100\n",
      "256/256 [==============================] - 0s 793us/step - loss: 0.5878 - accuracy: 0.6841\n",
      "Epoch 35/100\n",
      "256/256 [==============================] - 0s 735us/step - loss: 0.5877 - accuracy: 0.6824\n",
      "Epoch 36/100\n",
      "256/256 [==============================] - 0s 723us/step - loss: 0.5866 - accuracy: 0.6849\n",
      "Epoch 37/100\n",
      "256/256 [==============================] - 0s 719us/step - loss: 0.5859 - accuracy: 0.6839\n",
      "Epoch 38/100\n",
      "256/256 [==============================] - 0s 731us/step - loss: 0.5856 - accuracy: 0.6861\n",
      "Epoch 39/100\n",
      "256/256 [==============================] - 0s 741us/step - loss: 0.5839 - accuracy: 0.6861\n",
      "Epoch 40/100\n",
      "256/256 [==============================] - 0s 728us/step - loss: 0.5837 - accuracy: 0.6850\n",
      "Epoch 41/100\n",
      "256/256 [==============================] - 0s 753us/step - loss: 0.5827 - accuracy: 0.6854\n",
      "Epoch 42/100\n",
      "256/256 [==============================] - 0s 718us/step - loss: 0.5808 - accuracy: 0.6876\n",
      "Epoch 43/100\n",
      "256/256 [==============================] - 0s 786us/step - loss: 0.5798 - accuracy: 0.6863\n",
      "Epoch 44/100\n",
      "256/256 [==============================] - 0s 752us/step - loss: 0.5784 - accuracy: 0.6864\n",
      "Epoch 45/100\n",
      "256/256 [==============================] - 0s 760us/step - loss: 0.5788 - accuracy: 0.6852\n",
      "Epoch 46/100\n",
      "256/256 [==============================] - 0s 739us/step - loss: 0.5772 - accuracy: 0.6901\n",
      "Epoch 47/100\n",
      "256/256 [==============================] - 0s 711us/step - loss: 0.5769 - accuracy: 0.6855\n",
      "Epoch 48/100\n",
      "256/256 [==============================] - 0s 735us/step - loss: 0.5747 - accuracy: 0.6894\n",
      "Epoch 49/100\n",
      "256/256 [==============================] - 0s 757us/step - loss: 0.5753 - accuracy: 0.6842\n",
      "Epoch 50/100\n",
      "256/256 [==============================] - 0s 740us/step - loss: 0.5738 - accuracy: 0.6875\n",
      "Epoch 51/100\n",
      "256/256 [==============================] - 0s 817us/step - loss: 0.5722 - accuracy: 0.6893\n",
      "Epoch 52/100\n",
      "256/256 [==============================] - 0s 723us/step - loss: 0.5729 - accuracy: 0.6876\n",
      "Epoch 53/100\n",
      "256/256 [==============================] - 0s 774us/step - loss: 0.5716 - accuracy: 0.6908\n",
      "Epoch 54/100\n",
      "256/256 [==============================] - 0s 754us/step - loss: 0.5700 - accuracy: 0.6850\n",
      "Epoch 55/100\n",
      "256/256 [==============================] - 0s 743us/step - loss: 0.5704 - accuracy: 0.6893\n",
      "Epoch 56/100\n",
      "256/256 [==============================] - 0s 739us/step - loss: 0.5694 - accuracy: 0.6890\n",
      "Epoch 57/100\n",
      "256/256 [==============================] - 0s 727us/step - loss: 0.5685 - accuracy: 0.6927\n",
      "Epoch 58/100\n",
      "256/256 [==============================] - 0s 723us/step - loss: 0.5685 - accuracy: 0.6903\n",
      "Epoch 59/100\n",
      "256/256 [==============================] - 0s 739us/step - loss: 0.5664 - accuracy: 0.6903\n",
      "Epoch 60/100\n",
      "256/256 [==============================] - 0s 727us/step - loss: 0.5665 - accuracy: 0.6905\n",
      "Epoch 61/100\n",
      "256/256 [==============================] - 0s 731us/step - loss: 0.5655 - accuracy: 0.6927\n",
      "Epoch 62/100\n",
      "256/256 [==============================] - 0s 739us/step - loss: 0.5643 - accuracy: 0.6920\n",
      "Epoch 63/100\n",
      "256/256 [==============================] - 0s 718us/step - loss: 0.5645 - accuracy: 0.6924\n",
      "Epoch 64/100\n",
      "256/256 [==============================] - 0s 735us/step - loss: 0.5645 - accuracy: 0.6909\n",
      "Epoch 65/100\n",
      "256/256 [==============================] - 0s 727us/step - loss: 0.5638 - accuracy: 0.6908\n",
      "Epoch 66/100\n",
      "256/256 [==============================] - 0s 726us/step - loss: 0.5635 - accuracy: 0.6896\n",
      "Epoch 67/100\n",
      "256/256 [==============================] - 0s 723us/step - loss: 0.5625 - accuracy: 0.6925\n",
      "Epoch 68/100\n",
      "256/256 [==============================] - 0s 739us/step - loss: 0.5623 - accuracy: 0.6914\n",
      "Epoch 69/100\n",
      "256/256 [==============================] - 0s 723us/step - loss: 0.5615 - accuracy: 0.6907\n",
      "Epoch 70/100\n",
      "256/256 [==============================] - 0s 743us/step - loss: 0.5608 - accuracy: 0.6925\n",
      "Epoch 71/100\n",
      "256/256 [==============================] - 0s 743us/step - loss: 0.5597 - accuracy: 0.6945\n",
      "Epoch 72/100\n",
      "256/256 [==============================] - 0s 727us/step - loss: 0.5605 - accuracy: 0.6951\n",
      "Epoch 73/100\n",
      "256/256 [==============================] - 0s 718us/step - loss: 0.5588 - accuracy: 0.6908\n",
      "Epoch 74/100\n",
      "256/256 [==============================] - 0s 743us/step - loss: 0.5595 - accuracy: 0.6918\n",
      "Epoch 75/100\n",
      "256/256 [==============================] - 0s 735us/step - loss: 0.5574 - accuracy: 0.6929\n",
      "Epoch 76/100\n",
      "256/256 [==============================] - 0s 825us/step - loss: 0.5579 - accuracy: 0.6945\n",
      "Epoch 77/100\n",
      "256/256 [==============================] - 0s 836us/step - loss: 0.5569 - accuracy: 0.6979\n",
      "Epoch 78/100\n",
      "256/256 [==============================] - 0s 844us/step - loss: 0.5576 - accuracy: 0.6968\n",
      "Epoch 79/100\n",
      "256/256 [==============================] - 0s 805us/step - loss: 0.5565 - accuracy: 0.6952\n",
      "Epoch 80/100\n",
      "256/256 [==============================] - 0s 761us/step - loss: 0.5563 - accuracy: 0.6959\n",
      "Epoch 81/100\n",
      "256/256 [==============================] - 0s 772us/step - loss: 0.5566 - accuracy: 0.6963\n",
      "Epoch 82/100\n",
      "256/256 [==============================] - 0s 747us/step - loss: 0.5562 - accuracy: 0.6914\n",
      "Epoch 83/100\n",
      "256/256 [==============================] - 0s 750us/step - loss: 0.5552 - accuracy: 0.6971\n",
      "Epoch 84/100\n",
      "256/256 [==============================] - 0s 770us/step - loss: 0.5553 - accuracy: 0.6947\n",
      "Epoch 85/100\n",
      "256/256 [==============================] - 0s 743us/step - loss: 0.5537 - accuracy: 0.6976\n",
      "Epoch 86/100\n",
      "256/256 [==============================] - 0s 739us/step - loss: 0.5542 - accuracy: 0.6996\n",
      "Epoch 87/100\n",
      "256/256 [==============================] - 0s 812us/step - loss: 0.5537 - accuracy: 0.6974\n",
      "Epoch 88/100\n",
      "256/256 [==============================] - 0s 858us/step - loss: 0.5534 - accuracy: 0.6967\n",
      "Epoch 89/100\n",
      "256/256 [==============================] - 0s 845us/step - loss: 0.5515 - accuracy: 0.6959\n",
      "Epoch 90/100\n",
      "256/256 [==============================] - 0s 817us/step - loss: 0.5526 - accuracy: 0.6962\n",
      "Epoch 91/100\n",
      "256/256 [==============================] - 0s 739us/step - loss: 0.5521 - accuracy: 0.6960\n",
      "Epoch 92/100\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.5511 - accuracy: 0.7003\n",
      "Epoch 93/100\n",
      "256/256 [==============================] - 0s 2ms/step - loss: 0.5514 - accuracy: 0.6962\n",
      "Epoch 94/100\n",
      "256/256 [==============================] - 0s 774us/step - loss: 0.5504 - accuracy: 0.6998\n",
      "Epoch 95/100\n",
      "256/256 [==============================] - 0s 740us/step - loss: 0.5503 - accuracy: 0.6990\n",
      "Epoch 96/100\n",
      "256/256 [==============================] - 0s 745us/step - loss: 0.5499 - accuracy: 0.7004\n",
      "Epoch 97/100\n",
      "256/256 [==============================] - 0s 747us/step - loss: 0.5492 - accuracy: 0.7018\n",
      "Epoch 98/100\n",
      "256/256 [==============================] - 0s 758us/step - loss: 0.5501 - accuracy: 0.6995\n",
      "Epoch 99/100\n",
      "256/256 [==============================] - 0s 782us/step - loss: 0.5474 - accuracy: 0.7023\n",
      "Epoch 100/100\n",
      "256/256 [==============================] - 0s 754us/step - loss: 0.5489 - accuracy: 0.6964\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Fit the model to the training data\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 - 0s - loss: 0.6201 - accuracy: 0.6580\n",
      "Loss: 0.6201411485671997, Accuracy: 0.6579912304878235\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I think Easy Ensemble Classifier is the winner!"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6bbbf46ac35b3752c751a75b1a32432224dacc405cb55dd51db559f1ccadb36c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('PyData': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
