{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size_l</th>\n",
       "      <th>og</th>\n",
       "      <th>fg</th>\n",
       "      <th>abv</th>\n",
       "      <th>ibu</th>\n",
       "      <th>color</th>\n",
       "      <th>boilsize</th>\n",
       "      <th>boiltime</th>\n",
       "      <th>boilgravity</th>\n",
       "      <th>efficiency</th>\n",
       "      <th>mashthickness</th>\n",
       "      <th>pitchrate</th>\n",
       "      <th>primarytemp</th>\n",
       "      <th>review_taste</th>\n",
       "      <th>beer_abv</th>\n",
       "      <th>sugarscale_Plato</th>\n",
       "      <th>sugarscale_Specific Gravity</th>\n",
       "      <th>brewmethod_All Grain</th>\n",
       "      <th>brewmethod_BIAB</th>\n",
       "      <th>brewmethod_Partial Mash</th>\n",
       "      <th>brewmethod_extract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.93</td>\n",
       "      <td>1.082</td>\n",
       "      <td>1.013</td>\n",
       "      <td>9.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.10</td>\n",
       "      <td>21.58</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.103825</td>\n",
       "      <td>7.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.57</td>\n",
       "      <td>1.076</td>\n",
       "      <td>1.014</td>\n",
       "      <td>8.10</td>\n",
       "      <td>33.51</td>\n",
       "      <td>3.68</td>\n",
       "      <td>8.71</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.066</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.103825</td>\n",
       "      <td>7.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.82</td>\n",
       "      <td>1.043</td>\n",
       "      <td>1.011</td>\n",
       "      <td>4.14</td>\n",
       "      <td>13.22</td>\n",
       "      <td>17.67</td>\n",
       "      <td>28.39</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>12.22</td>\n",
       "      <td>3.028652</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22.71</td>\n",
       "      <td>1.069</td>\n",
       "      <td>1.017</td>\n",
       "      <td>6.75</td>\n",
       "      <td>58.76</td>\n",
       "      <td>40.00</td>\n",
       "      <td>29.34</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.053</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.265971</td>\n",
       "      <td>6.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22.71</td>\n",
       "      <td>1.068</td>\n",
       "      <td>1.018</td>\n",
       "      <td>6.53</td>\n",
       "      <td>73.40</td>\n",
       "      <td>40.00</td>\n",
       "      <td>27.44</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.056</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.25</td>\n",
       "      <td>18.89</td>\n",
       "      <td>4.265971</td>\n",
       "      <td>6.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   size_l     og     fg   abv    ibu  color  boilsize  boiltime  boilgravity  \\\n",
       "0   18.93  1.082  1.013  9.10   0.00   4.10     21.58      60.0        0.000   \n",
       "1    7.57  1.076  1.014  8.10  33.51   3.68      8.71      60.0        1.066   \n",
       "2   20.82  1.043  1.011  4.14  13.22  17.67     28.39      90.0        0.000   \n",
       "3   22.71  1.069  1.017  6.75  58.76  40.00     29.34      90.0        1.053   \n",
       "4   22.71  1.068  1.018  6.53  73.40  40.00     27.44      90.0        1.056   \n",
       "\n",
       "   efficiency  mashthickness  pitchrate  primarytemp  review_taste  beer_abv  \\\n",
       "0        72.0            0.0       0.00         0.00      4.103825       7.6   \n",
       "1        75.0            0.0       0.00         0.00      4.103825       7.6   \n",
       "2        85.0            0.0       1.75        12.22      3.028652       4.4   \n",
       "3        70.0            0.0       0.00         0.00      4.265971       6.4   \n",
       "4        65.0            1.3       1.25        18.89      4.265971       6.4   \n",
       "\n",
       "   sugarscale_Plato  sugarscale_Specific Gravity  brewmethod_All Grain  \\\n",
       "0               0.0                          1.0                   1.0   \n",
       "1               0.0                          1.0                   1.0   \n",
       "2               0.0                          1.0                   1.0   \n",
       "3               0.0                          1.0                   1.0   \n",
       "4               0.0                          1.0                   1.0   \n",
       "\n",
       "   brewmethod_BIAB  brewmethod_Partial Mash  brewmethod_extract  \n",
       "0              0.0                      0.0                 0.0  \n",
       "1              0.0                      0.0                 0.0  \n",
       "2              0.0                      0.0                 0.0  \n",
       "3              0.0                      0.0                 0.0  \n",
       "4              0.0                      0.0                 0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_nb_df = pd.read_csv(\"merged_nb_df.csv\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "merged_nb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34.77543538038497"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What percentage of beers scored 4 or above?\n",
    "len(merged_nb_df[(merged_nb_df[\"review_taste\"]>=4)]) / len(merged_nb_df) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since beers with a rating of four or above is the top 34% of beers, let's go with those as \"good\" beers.\n",
    "# We need a new category \"good beer\" with a 1 for good and 0 for bad\n",
    "merged_nb_df[\"good_beer\"]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for all the \"good beers\", put a 1 in the good_beer column\n",
    "merged_nb_df.loc[merged_nb_df[\"review_taste\"].abs()>=4, \"good_beer\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size_l</th>\n",
       "      <th>og</th>\n",
       "      <th>fg</th>\n",
       "      <th>abv</th>\n",
       "      <th>ibu</th>\n",
       "      <th>color</th>\n",
       "      <th>boilsize</th>\n",
       "      <th>boiltime</th>\n",
       "      <th>boilgravity</th>\n",
       "      <th>efficiency</th>\n",
       "      <th>mashthickness</th>\n",
       "      <th>pitchrate</th>\n",
       "      <th>primarytemp</th>\n",
       "      <th>review_taste</th>\n",
       "      <th>beer_abv</th>\n",
       "      <th>sugarscale_Plato</th>\n",
       "      <th>sugarscale_Specific Gravity</th>\n",
       "      <th>brewmethod_All Grain</th>\n",
       "      <th>brewmethod_BIAB</th>\n",
       "      <th>brewmethod_Partial Mash</th>\n",
       "      <th>brewmethod_extract</th>\n",
       "      <th>good_beer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.93</td>\n",
       "      <td>1.082</td>\n",
       "      <td>1.013</td>\n",
       "      <td>9.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.10</td>\n",
       "      <td>21.58</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.103825</td>\n",
       "      <td>7.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.57</td>\n",
       "      <td>1.076</td>\n",
       "      <td>1.014</td>\n",
       "      <td>8.10</td>\n",
       "      <td>33.51</td>\n",
       "      <td>3.68</td>\n",
       "      <td>8.71</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.066</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.103825</td>\n",
       "      <td>7.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.82</td>\n",
       "      <td>1.043</td>\n",
       "      <td>1.011</td>\n",
       "      <td>4.14</td>\n",
       "      <td>13.22</td>\n",
       "      <td>17.67</td>\n",
       "      <td>28.39</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>12.22</td>\n",
       "      <td>3.028652</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22.71</td>\n",
       "      <td>1.069</td>\n",
       "      <td>1.017</td>\n",
       "      <td>6.75</td>\n",
       "      <td>58.76</td>\n",
       "      <td>40.00</td>\n",
       "      <td>29.34</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.053</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.265971</td>\n",
       "      <td>6.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22.71</td>\n",
       "      <td>1.068</td>\n",
       "      <td>1.018</td>\n",
       "      <td>6.53</td>\n",
       "      <td>73.40</td>\n",
       "      <td>40.00</td>\n",
       "      <td>27.44</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.056</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.25</td>\n",
       "      <td>18.89</td>\n",
       "      <td>4.265971</td>\n",
       "      <td>6.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   size_l     og     fg   abv    ibu  color  boilsize  boiltime  boilgravity  \\\n",
       "0   18.93  1.082  1.013  9.10   0.00   4.10     21.58      60.0        0.000   \n",
       "1    7.57  1.076  1.014  8.10  33.51   3.68      8.71      60.0        1.066   \n",
       "2   20.82  1.043  1.011  4.14  13.22  17.67     28.39      90.0        0.000   \n",
       "3   22.71  1.069  1.017  6.75  58.76  40.00     29.34      90.0        1.053   \n",
       "4   22.71  1.068  1.018  6.53  73.40  40.00     27.44      90.0        1.056   \n",
       "\n",
       "   efficiency  mashthickness  pitchrate  primarytemp  review_taste  beer_abv  \\\n",
       "0        72.0            0.0       0.00         0.00      4.103825       7.6   \n",
       "1        75.0            0.0       0.00         0.00      4.103825       7.6   \n",
       "2        85.0            0.0       1.75        12.22      3.028652       4.4   \n",
       "3        70.0            0.0       0.00         0.00      4.265971       6.4   \n",
       "4        65.0            1.3       1.25        18.89      4.265971       6.4   \n",
       "\n",
       "   sugarscale_Plato  sugarscale_Specific Gravity  brewmethod_All Grain  \\\n",
       "0               0.0                          1.0                   1.0   \n",
       "1               0.0                          1.0                   1.0   \n",
       "2               0.0                          1.0                   1.0   \n",
       "3               0.0                          1.0                   1.0   \n",
       "4               0.0                          1.0                   1.0   \n",
       "\n",
       "   brewmethod_BIAB  brewmethod_Partial Mash  brewmethod_extract  good_beer  \n",
       "0              0.0                      0.0                 0.0          1  \n",
       "1              0.0                      0.0                 0.0          1  \n",
       "2              0.0                      0.0                 0.0          0  \n",
       "3              0.0                      0.0                 0.0          1  \n",
       "4              0.0                      0.0                 0.0          1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_nb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "beer_class = merged_nb_df.drop(columns = [\"review_taste\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = beer_class.good_beer.values\n",
    "X = beer_class.drop(columns = [\"good_beer\"]).values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=5, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Random forest predictive accuracy: 0.613\n"
     ]
    }
   ],
   "source": [
    "# Create a random forest classifier.\n",
    "rf_model = RandomForestClassifier(n_estimators=200, random_state=5)\n",
    "\n",
    "# Fitting the model\n",
    "rf_model = rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = rf_model.predict(X_test_scaled)\n",
    "print(f\" Random forest predictive accuracy: {accuracy_score(y_test,y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.69      0.74      0.37      0.71      0.52      0.28      1779\n",
      "          1       0.43      0.37      0.74      0.40      0.52      0.26       949\n",
      "\n",
      "avg / total       0.60      0.61      0.50      0.60      0.52      0.28      2728\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the imbalanced classification report\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Easy Ensemble Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EasyEnsembleClassifier(n_estimators=100, random_state=1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the EasyEnsembleClassifier\n",
    "classifier = EasyEnsembleClassifier(n_estimators = 100, random_state=1)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.6873167155425219\n"
     ]
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "predictions = classifier.predict(X_test)\n",
    "acc_score = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy Score : {acc_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>1284</td>\n",
       "      <td>495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>358</td>\n",
       "      <td>591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0         1284          495\n",
       "Actual 1          358          591"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual 0\", \"Actual 1\"],\n",
    "    columns=[\"Predicted 0\", \"Predicted 1\"]\n",
    ")\n",
    "\n",
    "# Displaying results\n",
    "display(cm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.78      0.72      0.62      0.75      0.67      0.45      1779\n",
      "          1       0.54      0.62      0.72      0.58      0.67      0.45       949\n",
      "\n",
      "avg / total       0.70      0.69      0.66      0.69      0.67      0.45      2728\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the imbalanced classification report\n",
    "print(\"Classification Report\")\n",
    "print(classification_report_imbalanced(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 100)               2100      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 7,201\n",
      "Trainable params: 7,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = 20\n",
    "hidden_nodes_layer1 = 100\n",
    "hidden_nodes_layer2 = 50\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the Sequential model together and customize metrics\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "256/256 [==============================] - 0s 743us/step - loss: 0.6392 - accuracy: 0.6480\n",
      "Epoch 2/150\n",
      "256/256 [==============================] - 0s 762us/step - loss: 0.6242 - accuracy: 0.6557\n",
      "Epoch 3/150\n",
      "256/256 [==============================] - 0s 758us/step - loss: 0.6201 - accuracy: 0.6611\n",
      "Epoch 4/150\n",
      "256/256 [==============================] - 0s 762us/step - loss: 0.6163 - accuracy: 0.6607\n",
      "Epoch 5/150\n",
      "256/256 [==============================] - 0s 743us/step - loss: 0.6143 - accuracy: 0.6681\n",
      "Epoch 6/150\n",
      "256/256 [==============================] - 0s 809us/step - loss: 0.6126 - accuracy: 0.6704\n",
      "Epoch 7/150\n",
      "256/256 [==============================] - 0s 757us/step - loss: 0.6117 - accuracy: 0.6694\n",
      "Epoch 8/150\n",
      "256/256 [==============================] - 0s 743us/step - loss: 0.6096 - accuracy: 0.6742\n",
      "Epoch 9/150\n",
      "256/256 [==============================] - 0s 805us/step - loss: 0.6094 - accuracy: 0.6716\n",
      "Epoch 10/150\n",
      "256/256 [==============================] - 0s 852us/step - loss: 0.6060 - accuracy: 0.6780\n",
      "Epoch 11/150\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.6046 - accuracy: 0.6797\n",
      "Epoch 12/150\n",
      "256/256 [==============================] - 0s 829us/step - loss: 0.6024 - accuracy: 0.6771\n",
      "Epoch 13/150\n",
      "256/256 [==============================] - 0s 876us/step - loss: 0.6009 - accuracy: 0.6787\n",
      "Epoch 14/150\n",
      "256/256 [==============================] - 0s 750us/step - loss: 0.5994 - accuracy: 0.6819\n",
      "Epoch 15/150\n",
      "256/256 [==============================] - 0s 778us/step - loss: 0.5987 - accuracy: 0.6821\n",
      "Epoch 16/150\n",
      "256/256 [==============================] - 0s 692us/step - loss: 0.5971 - accuracy: 0.6842\n",
      "Epoch 17/150\n",
      "256/256 [==============================] - 0s 695us/step - loss: 0.5957 - accuracy: 0.6846\n",
      "Epoch 18/150\n",
      "256/256 [==============================] - 0s 708us/step - loss: 0.5943 - accuracy: 0.6848\n",
      "Epoch 19/150\n",
      "256/256 [==============================] - 0s 707us/step - loss: 0.5919 - accuracy: 0.6850\n",
      "Epoch 20/150\n",
      "256/256 [==============================] - 0s 696us/step - loss: 0.5927 - accuracy: 0.6848\n",
      "Epoch 21/150\n",
      "256/256 [==============================] - 0s 684us/step - loss: 0.5896 - accuracy: 0.6857\n",
      "Epoch 22/150\n",
      "256/256 [==============================] - 0s 699us/step - loss: 0.5883 - accuracy: 0.6869\n",
      "Epoch 23/150\n",
      "256/256 [==============================] - 0s 684us/step - loss: 0.5861 - accuracy: 0.6863\n",
      "Epoch 24/150\n",
      "256/256 [==============================] - 0s 700us/step - loss: 0.5850 - accuracy: 0.6869\n",
      "Epoch 25/150\n",
      "256/256 [==============================] - 0s 704us/step - loss: 0.5829 - accuracy: 0.6880\n",
      "Epoch 26/150\n",
      "256/256 [==============================] - 0s 707us/step - loss: 0.5823 - accuracy: 0.6904\n",
      "Epoch 27/150\n",
      "256/256 [==============================] - 0s 692us/step - loss: 0.5811 - accuracy: 0.6896\n",
      "Epoch 28/150\n",
      "256/256 [==============================] - 0s 676us/step - loss: 0.5787 - accuracy: 0.6891\n",
      "Epoch 29/150\n",
      "256/256 [==============================] - 0s 707us/step - loss: 0.5774 - accuracy: 0.6874\n",
      "Epoch 30/150\n",
      "256/256 [==============================] - 0s 692us/step - loss: 0.5747 - accuracy: 0.6858\n",
      "Epoch 31/150\n",
      "256/256 [==============================] - 0s 684us/step - loss: 0.5726 - accuracy: 0.6904\n",
      "Epoch 32/150\n",
      "256/256 [==============================] - 0s 700us/step - loss: 0.5713 - accuracy: 0.6886\n",
      "Epoch 33/150\n",
      "256/256 [==============================] - 0s 688us/step - loss: 0.5698 - accuracy: 0.6899\n",
      "Epoch 34/150\n",
      "256/256 [==============================] - 0s 700us/step - loss: 0.5677 - accuracy: 0.6885\n",
      "Epoch 35/150\n",
      "256/256 [==============================] - 0s 680us/step - loss: 0.5654 - accuracy: 0.6936\n",
      "Epoch 36/150\n",
      "256/256 [==============================] - 0s 696us/step - loss: 0.5665 - accuracy: 0.6935\n",
      "Epoch 37/150\n",
      "256/256 [==============================] - 0s 684us/step - loss: 0.5643 - accuracy: 0.6951\n",
      "Epoch 38/150\n",
      "256/256 [==============================] - 0s 714us/step - loss: 0.5627 - accuracy: 0.6967\n",
      "Epoch 39/150\n",
      "256/256 [==============================] - 0s 684us/step - loss: 0.5606 - accuracy: 0.6953\n",
      "Epoch 40/150\n",
      "256/256 [==============================] - 0s 696us/step - loss: 0.5596 - accuracy: 0.6963\n",
      "Epoch 41/150\n",
      "256/256 [==============================] - 0s 694us/step - loss: 0.5582 - accuracy: 0.6978\n",
      "Epoch 42/150\n",
      "256/256 [==============================] - 0s 706us/step - loss: 0.5577 - accuracy: 0.6945\n",
      "Epoch 43/150\n",
      "256/256 [==============================] - 0s 719us/step - loss: 0.5565 - accuracy: 0.6945\n",
      "Epoch 44/150\n",
      "256/256 [==============================] - 0s 685us/step - loss: 0.5551 - accuracy: 0.6989\n",
      "Epoch 45/150\n",
      "256/256 [==============================] - 0s 997us/step - loss: 0.5539 - accuracy: 0.7000\n",
      "Epoch 46/150\n",
      "256/256 [==============================] - 0s 715us/step - loss: 0.5540 - accuracy: 0.6976\n",
      "Epoch 47/150\n",
      "256/256 [==============================] - 0s 696us/step - loss: 0.5532 - accuracy: 0.6971\n",
      "Epoch 48/150\n",
      "256/256 [==============================] - 0s 707us/step - loss: 0.5513 - accuracy: 0.6996\n",
      "Epoch 49/150\n",
      "256/256 [==============================] - 0s 950us/step - loss: 0.5497 - accuracy: 0.6971\n",
      "Epoch 50/150\n",
      "256/256 [==============================] - 0s 750us/step - loss: 0.5501 - accuracy: 0.6980\n",
      "Epoch 51/150\n",
      "256/256 [==============================] - 0s 694us/step - loss: 0.5488 - accuracy: 0.6981\n",
      "Epoch 52/150\n",
      "256/256 [==============================] - 0s 700us/step - loss: 0.5480 - accuracy: 0.6995\n",
      "Epoch 53/150\n",
      "256/256 [==============================] - 0s 684us/step - loss: 0.5470 - accuracy: 0.6986\n",
      "Epoch 54/150\n",
      "256/256 [==============================] - 0s 684us/step - loss: 0.5476 - accuracy: 0.7006\n",
      "Epoch 55/150\n",
      "256/256 [==============================] - 0s 692us/step - loss: 0.5442 - accuracy: 0.7003\n",
      "Epoch 56/150\n",
      "256/256 [==============================] - 0s 696us/step - loss: 0.5443 - accuracy: 0.7044\n",
      "Epoch 57/150\n",
      "256/256 [==============================] - 0s 685us/step - loss: 0.5437 - accuracy: 0.7034\n",
      "Epoch 58/150\n",
      "256/256 [==============================] - 0s 731us/step - loss: 0.5435 - accuracy: 0.7030\n",
      "Epoch 59/150\n",
      "256/256 [==============================] - 0s 700us/step - loss: 0.5413 - accuracy: 0.7039\n",
      "Epoch 60/150\n",
      "256/256 [==============================] - 0s 684us/step - loss: 0.5419 - accuracy: 0.7030\n",
      "Epoch 61/150\n",
      "256/256 [==============================] - 0s 841us/step - loss: 0.5410 - accuracy: 0.7068\n",
      "Epoch 62/150\n",
      "256/256 [==============================] - 0s 717us/step - loss: 0.5411 - accuracy: 0.7052\n",
      "Epoch 63/150\n",
      "256/256 [==============================] - 0s 735us/step - loss: 0.5399 - accuracy: 0.7025\n",
      "Epoch 64/150\n",
      "256/256 [==============================] - 0s 718us/step - loss: 0.5386 - accuracy: 0.7053\n",
      "Epoch 65/150\n",
      "256/256 [==============================] - 0s 684us/step - loss: 0.5394 - accuracy: 0.7057\n",
      "Epoch 66/150\n",
      "256/256 [==============================] - 0s 696us/step - loss: 0.5375 - accuracy: 0.7025\n",
      "Epoch 67/150\n",
      "256/256 [==============================] - 0s 750us/step - loss: 0.5368 - accuracy: 0.7066\n",
      "Epoch 68/150\n",
      "256/256 [==============================] - 0s 696us/step - loss: 0.5365 - accuracy: 0.7053\n",
      "Epoch 69/150\n",
      "256/256 [==============================] - 0s 723us/step - loss: 0.5370 - accuracy: 0.7075\n",
      "Epoch 70/150\n",
      "256/256 [==============================] - 0s 719us/step - loss: 0.5347 - accuracy: 0.7074\n",
      "Epoch 71/150\n",
      "256/256 [==============================] - 0s 696us/step - loss: 0.5350 - accuracy: 0.7078\n",
      "Epoch 72/150\n",
      "256/256 [==============================] - 0s 711us/step - loss: 0.5352 - accuracy: 0.7066\n",
      "Epoch 73/150\n",
      "256/256 [==============================] - 0s 735us/step - loss: 0.5342 - accuracy: 0.7100\n",
      "Epoch 74/150\n",
      "256/256 [==============================] - 0s 700us/step - loss: 0.5324 - accuracy: 0.7091\n",
      "Epoch 75/150\n",
      "256/256 [==============================] - 0s 988us/step - loss: 0.5330 - accuracy: 0.7078\n",
      "Epoch 76/150\n",
      "256/256 [==============================] - 0s 723us/step - loss: 0.5319 - accuracy: 0.7077\n",
      "Epoch 77/150\n",
      "256/256 [==============================] - 0s 696us/step - loss: 0.5323 - accuracy: 0.7091\n",
      "Epoch 78/150\n",
      "256/256 [==============================] - 0s 704us/step - loss: 0.5302 - accuracy: 0.7099\n",
      "Epoch 79/150\n",
      "256/256 [==============================] - 0s 715us/step - loss: 0.5304 - accuracy: 0.7056\n",
      "Epoch 80/150\n",
      "256/256 [==============================] - 0s 702us/step - loss: 0.5302 - accuracy: 0.7118\n",
      "Epoch 81/150\n",
      "256/256 [==============================] - 0s 696us/step - loss: 0.5284 - accuracy: 0.7094\n",
      "Epoch 82/150\n",
      "256/256 [==============================] - 0s 696us/step - loss: 0.5274 - accuracy: 0.7111\n",
      "Epoch 83/150\n",
      "256/256 [==============================] - 0s 709us/step - loss: 0.5291 - accuracy: 0.7117\n",
      "Epoch 84/150\n",
      "256/256 [==============================] - 0s 700us/step - loss: 0.5282 - accuracy: 0.7101\n",
      "Epoch 85/150\n",
      "256/256 [==============================] - 0s 684us/step - loss: 0.5262 - accuracy: 0.7129\n",
      "Epoch 86/150\n",
      "256/256 [==============================] - 0s 711us/step - loss: 0.5259 - accuracy: 0.7103\n",
      "Epoch 87/150\n",
      "256/256 [==============================] - 0s 702us/step - loss: 0.5259 - accuracy: 0.7108\n",
      "Epoch 88/150\n",
      "256/256 [==============================] - 0s 700us/step - loss: 0.5260 - accuracy: 0.7097\n",
      "Epoch 89/150\n",
      "256/256 [==============================] - 0s 700us/step - loss: 0.5227 - accuracy: 0.7151\n",
      "Epoch 90/150\n",
      "256/256 [==============================] - 0s 701us/step - loss: 0.5259 - accuracy: 0.7135\n",
      "Epoch 91/150\n",
      "256/256 [==============================] - 0s 707us/step - loss: 0.5221 - accuracy: 0.7134\n",
      "Epoch 92/150\n",
      "256/256 [==============================] - 0s 715us/step - loss: 0.5231 - accuracy: 0.7134\n",
      "Epoch 93/150\n",
      "256/256 [==============================] - 0s 696us/step - loss: 0.5230 - accuracy: 0.7145\n",
      "Epoch 94/150\n",
      "256/256 [==============================] - 0s 774us/step - loss: 0.5223 - accuracy: 0.7121\n",
      "Epoch 95/150\n",
      "256/256 [==============================] - 0s 720us/step - loss: 0.5203 - accuracy: 0.7134\n",
      "Epoch 96/150\n",
      "256/256 [==============================] - 0s 727us/step - loss: 0.5215 - accuracy: 0.7161\n",
      "Epoch 97/150\n",
      "256/256 [==============================] - 0s 696us/step - loss: 0.5205 - accuracy: 0.7147\n",
      "Epoch 98/150\n",
      "256/256 [==============================] - 0s 700us/step - loss: 0.5198 - accuracy: 0.7158\n",
      "Epoch 99/150\n",
      "256/256 [==============================] - 0s 743us/step - loss: 0.5209 - accuracy: 0.7176\n",
      "Epoch 100/150\n",
      "256/256 [==============================] - 0s 711us/step - loss: 0.5189 - accuracy: 0.7133\n",
      "Epoch 101/150\n",
      "256/256 [==============================] - 0s 700us/step - loss: 0.5195 - accuracy: 0.7179\n",
      "Epoch 102/150\n",
      "256/256 [==============================] - 0s 731us/step - loss: 0.5175 - accuracy: 0.7167\n",
      "Epoch 103/150\n",
      "256/256 [==============================] - 0s 700us/step - loss: 0.5171 - accuracy: 0.7221\n",
      "Epoch 104/150\n",
      "256/256 [==============================] - 0s 692us/step - loss: 0.5178 - accuracy: 0.7158\n",
      "Epoch 105/150\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.5163 - accuracy: 0.7191\n",
      "Epoch 106/150\n",
      "256/256 [==============================] - 0s 693us/step - loss: 0.5181 - accuracy: 0.7163\n",
      "Epoch 107/150\n",
      "256/256 [==============================] - 0s 714us/step - loss: 0.5174 - accuracy: 0.7143\n",
      "Epoch 108/150\n",
      "256/256 [==============================] - 0s 719us/step - loss: 0.5166 - accuracy: 0.7156\n",
      "Epoch 109/150\n",
      "256/256 [==============================] - 0s 696us/step - loss: 0.5151 - accuracy: 0.7216\n",
      "Epoch 110/150\n",
      "256/256 [==============================] - 0s 759us/step - loss: 0.5141 - accuracy: 0.7179\n",
      "Epoch 111/150\n",
      "256/256 [==============================] - 0s 692us/step - loss: 0.5142 - accuracy: 0.7222\n",
      "Epoch 112/150\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.5143 - accuracy: 0.7201\n",
      "Epoch 113/150\n",
      "256/256 [==============================] - 0s 690us/step - loss: 0.5138 - accuracy: 0.7202\n",
      "Epoch 114/150\n",
      "256/256 [==============================] - 0s 678us/step - loss: 0.5136 - accuracy: 0.7217\n",
      "Epoch 115/150\n",
      "256/256 [==============================] - 0s 691us/step - loss: 0.5150 - accuracy: 0.7202\n",
      "Epoch 116/150\n",
      "256/256 [==============================] - 0s 704us/step - loss: 0.5132 - accuracy: 0.7173\n",
      "Epoch 117/150\n",
      "256/256 [==============================] - 0s 680us/step - loss: 0.5127 - accuracy: 0.7180\n",
      "Epoch 118/150\n",
      "256/256 [==============================] - 0s 700us/step - loss: 0.5106 - accuracy: 0.7229\n",
      "Epoch 119/150\n",
      "256/256 [==============================] - 0s 719us/step - loss: 0.5105 - accuracy: 0.7207\n",
      "Epoch 120/150\n",
      "256/256 [==============================] - 0s 739us/step - loss: 0.5092 - accuracy: 0.7223\n",
      "Epoch 121/150\n",
      "256/256 [==============================] - 0s 817us/step - loss: 0.5109 - accuracy: 0.7228\n",
      "Epoch 122/150\n",
      "256/256 [==============================] - 0s 975us/step - loss: 0.5104 - accuracy: 0.7224\n",
      "Epoch 123/150\n",
      "256/256 [==============================] - 0s 959us/step - loss: 0.5098 - accuracy: 0.7231\n",
      "Epoch 124/150\n",
      "256/256 [==============================] - 0s 989us/step - loss: 0.5105 - accuracy: 0.7196\n",
      "Epoch 125/150\n",
      "256/256 [==============================] - 0s 965us/step - loss: 0.5073 - accuracy: 0.7251\n",
      "Epoch 126/150\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.5074 - accuracy: 0.7233\n",
      "Epoch 127/150\n",
      "256/256 [==============================] - 0s 942us/step - loss: 0.5085 - accuracy: 0.7243\n",
      "Epoch 128/150\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.5086 - accuracy: 0.7243\n",
      "Epoch 129/150\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.5085 - accuracy: 0.7211\n",
      "Epoch 130/150\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.5065 - accuracy: 0.7270\n",
      "Epoch 131/150\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.5081 - accuracy: 0.7271\n",
      "Epoch 132/150\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.5065 - accuracy: 0.7249\n",
      "Epoch 133/150\n",
      "256/256 [==============================] - 0s 950us/step - loss: 0.5065 - accuracy: 0.7249\n",
      "Epoch 134/150\n",
      "256/256 [==============================] - 0s 993us/step - loss: 0.5071 - accuracy: 0.7211\n",
      "Epoch 135/150\n",
      "256/256 [==============================] - 0s 961us/step - loss: 0.5038 - accuracy: 0.7232\n",
      "Epoch 136/150\n",
      "256/256 [==============================] - 0s 952us/step - loss: 0.5063 - accuracy: 0.7250\n",
      "Epoch 137/150\n",
      "256/256 [==============================] - 0s 958us/step - loss: 0.5052 - accuracy: 0.7255\n",
      "Epoch 138/150\n",
      "256/256 [==============================] - 0s 954us/step - loss: 0.5046 - accuracy: 0.7235\n",
      "Epoch 139/150\n",
      "256/256 [==============================] - 0s 969us/step - loss: 0.5037 - accuracy: 0.7289\n",
      "Epoch 140/150\n",
      "256/256 [==============================] - 0s 954us/step - loss: 0.5056 - accuracy: 0.7196\n",
      "Epoch 141/150\n",
      "256/256 [==============================] - 0s 970us/step - loss: 0.5040 - accuracy: 0.7262\n",
      "Epoch 142/150\n",
      "256/256 [==============================] - 0s 954us/step - loss: 0.5047 - accuracy: 0.7283\n",
      "Epoch 143/150\n",
      "256/256 [==============================] - 0s 983us/step - loss: 0.5026 - accuracy: 0.7284\n",
      "Epoch 144/150\n",
      "256/256 [==============================] - 0s 981us/step - loss: 0.5018 - accuracy: 0.7278\n",
      "Epoch 145/150\n",
      "256/256 [==============================] - 0s 969us/step - loss: 0.5040 - accuracy: 0.7243\n",
      "Epoch 146/150\n",
      "256/256 [==============================] - 0s 968us/step - loss: 0.5031 - accuracy: 0.7256\n",
      "Epoch 147/150\n",
      "256/256 [==============================] - 0s 970us/step - loss: 0.5024 - accuracy: 0.7237\n",
      "Epoch 148/150\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.5016 - accuracy: 0.7243\n",
      "Epoch 149/150\n",
      "256/256 [==============================] - 0s 938us/step - loss: 0.5006 - accuracy: 0.7245\n",
      "Epoch 150/150\n",
      "256/256 [==============================] - 0s 1ms/step - loss: 0.5035 - accuracy: 0.7253\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Fit the model to the training data\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 - 0s - loss: 0.6787 - accuracy: 0.6422\n",
      "Loss: 0.6787494421005249, Accuracy: 0.6422287225723267\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I think Easy Ensemble Classifier is the winner!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6bbbf46ac35b3752c751a75b1a32432224dacc405cb55dd51db559f1ccadb36c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('PyData': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
